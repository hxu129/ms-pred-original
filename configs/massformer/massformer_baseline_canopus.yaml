launcher_args: {experiment_name: massformer_baseline_canopus_train_public,
  script_name: "src/ms_pred/massformer_pred/train.py",
  slurm_script: launcher_scripts/generic_slurm.sh, 
  launch_method: local,
  visible_devices: [2],
}
universal_args:
  _slurm_args:
  - {_num_gpu: 1, cpus-per-task: 7, job-name: forward_train, mem-per-cpu: 8G,
    time: '1-18:00:00'}
  debug: [false]
  gpu: [True]

  seed: [1]
  num-workers: [16]
  batch-size: [128]
  max-epochs: [200]

  dataset-name: [canopus_train_public]
  split-name: [split_1.tsv] 

  learning-rate: [0.00014]
  lr-decay-rate: [0.853]
  num-bins: [15000] 
  loss-fn: [cosine]

  use-reverse: [true]

  # Reinit all layers, which means non can be fixed
  gf-fix-num-pt-layers: [0]
  gf-reinit-num-pt-layers: [-1]
  gf-reinit-layernorm: [True]
  gf-model-name: [graphormer_base]
  gf-pretrain-name: [pcqm4mv2_graphormer_base]

  # Optimize this
  mf-num-ff-num-layers: [1]
  mf-ff-h-dim: [1024]
  mf-dropout: [0.1]

  mf-ff-skip: [true]
  mf-layer-type: [neims]

  weight-decay: [1e-7]

  form-dir-name: ['no_subform.hdf5']
  embed-adduct: [true]
  embed-collision-energy: [false]

iterative_args:
  -  split-name: [split_1.tsv]
     save-dir: [split_1_rnd1]
     seed: [1]
  -  split-name: [split_1.tsv]
     save-dir: [split_1_rnd2]
     seed: [2]
  -  split-name: [split_1.tsv]
     save-dir: [split_1_rnd3]
     seed: [3]
